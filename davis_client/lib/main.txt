import 'package:flutter/material.dart';
import 'package:record/record.dart';
import 'package:audioplayers/audioplayers.dart';
import 'package:path_provider/path_provider.dart';
import 'dart:async';

void main() {
  runApp(const MyApp());
}

class MyApp extends StatelessWidget {
  const MyApp({super.key});

  @override
  Widget build(BuildContext context) {
    return MaterialApp(debugShowCheckedModeBanner: false, home: SpeechApp());
  }
}

class SpeechApp extends StatefulWidget {
  @override
  _SpeechAppState createState() => _SpeechAppState();
}

class _SpeechAppState extends State<SpeechApp> {
  String displayText = "Hold to Speak";
  bool isRecording = false;
  bool hasMicPermission = false;
  final record = AudioRecorder();
  final audioPlayer = AudioPlayer();
  String? recordedFilePath;
  DateTime? recordingStartTime;

  @override
  void initState() {
    super.initState();
    _checkPermission(); // Check permission when the app starts
  }

  /// Checks microphone permission on app start
  Future<void> _checkPermission() async {
    bool granted = await record.hasPermission();
    setState(() {
      hasMicPermission = granted;
    });
    debugPrint("Microphone permission granted: $hasMicPermission");
  }

  /// Plays a short beep sound
  Future<void> _playBeep() async {
    await audioPlayer.play(
      AssetSource('start.wav'),
    ); // Add a short beep sound to assets
  }

  /// Plays a short beep sound
  Future<void> _playBop() async {
    await audioPlayer.play(
      AssetSource('stop.wav'),
    ); // Add a short beep sound to assets
  }

  /// Starts recording audio
  Future<void> _startRecording() async {
    if (!hasMicPermission) {
      debugPrint("Microphone permission denied.");
      return;
    }

    debugPrint("onLongPress detected! Starting recording...");
    _playBeep(); // Play start sound

    setState(() {
      displayText = "Listening...";
      isRecording = true;
    });

    final dir = await getTemporaryDirectory();
    recordedFilePath = "${dir.path}/recorded_audio.m4a";
    recordingStartTime = DateTime.now();

    try {
      await record.start(
        const RecordConfig(encoder: AudioEncoder.aacLc, bitRate: 128000),
        path: recordedFilePath!,
      );
      debugPrint("Recording started successfully at $recordedFilePath");
    } catch (e) {
      debugPrint("Failed to start recording: $e");
    }
  }

  /// Stops recording and processes it
  Future<void> _stopRecordingAndProcess() async {
    debugPrint("onLongPressUp detected! Stopping recording...");

    if (!isRecording) return;

    DateTime recordingEndTime = DateTime.now();
    int durationMillis =
        recordingEndTime.difference(recordingStartTime!).inMilliseconds;

    setState(() {
      displayText = "Thinking...";
      isRecording = false;
    });

    _playBop(); // Play stop sound
    await record.stop();
    debugPrint("Recording stopped. File saved at: $recordedFilePath");

    if (durationMillis < 1000) {
      debugPrint("Recording too short (<1s), discarding.");
      setState(() {
        displayText = "Hold to Speak";
      });
      return;
    }

    // Simulate processing delay (fake API request)
    String processedAudioPath = await _fakeApiRequest(recordedFilePath!);

    // Play back the "processed" audio
    await _playAudio(processedAudioPath);

    setState(() {
      displayText = "Hold to Speak";
    });
  }

  /// Simulated API Request (Just returns the same audio file)
  Future<String> _fakeApiRequest(String filePath) async {
    debugPrint("Simulating API request...");
    await Future.delayed(const Duration(seconds: 2)); // Simulate delay
    debugPrint("API request completed. Returning same audio file.");
    return filePath; // Just return the recorded file
  }

  /// Plays the recorded audio
  Future<void> _playAudio(String filePath) async {
    debugPrint("Playing processed audio...");
    await audioPlayer.play(DeviceFileSource(filePath));
    await Future.delayed(const Duration(seconds: 2));
    debugPrint("Audio playback finished.");
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      backgroundColor: Colors.black,
      body: GestureDetector(
        behavior: HitTestBehavior.opaque, // Ensures full screen detection
        onLongPress: hasMicPermission ? _startRecording : null,
        onLongPressUp: hasMicPermission ? _stopRecordingAndProcess : null,
        child: Center(
          child: Text(
            displayText,
            key: ValueKey<String>(displayText),
            style: const TextStyle(
              fontSize: 36,
              fontWeight: FontWeight.bold,
              color: Colors.white,
            ),
            textAlign: TextAlign.center,
          ),
        ),
      ),
    );
  }
}
